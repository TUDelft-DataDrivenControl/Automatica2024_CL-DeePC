\section{Introduction}
Trends of increasing data availability as well as increasing system complexity provide opportunities for data driven-driven control%make a compelling case for data-driven control methods as an alternative to model-based approaches
~\citep{Hou2013}. In sharp contrast to the use of data in %Whilst data can be used with
indirect data-driven approaches to synthesise a model by means of system identification, direct data-driven control approaches are promising because they derive a control law directly from data without having to realize an explicit system model as an often expensive intermediate step~\citep{Hjalmarsson2005}.

A direct data-driven control method called \ac{DeePC} is developed in~\cite{Coulson2019} that relies on Willems' Fundamental Lemma in a receding horizon optimal control framework. This lemma reveals that for a deterministic \ac{LTI} system, any sufficiently persistently exciting input-output trajectory parameterizes all possible future input-output trajectories~\citep{Willems2005}. %
% 
% Since its conception in~\cite{Coulson2019}, a form of direct data-driven control called \ac{DeePC} has seen considerable development. \ac{DeePC} uses Willems' Fundamental Lemma from the field of behavioural systems theory, which states that for a deterministic system any sufficiently persistently exciting input-output trajectory parameterizes all possible future input-output trajectories~\cite{Willems2005}. In effect, \ac{DeePC} exploits Willems' Fundamental Lemma in a receding horizon optimal control framework found also in \ac{MPC}.
For non-deterministic systems, care has to be taken with such a parameterization in terms of only past input-output trajectories because this does not consider the effects of noise. If the block-Hankel data matrix in which the noisy input-output trajectories are stored is full rank then unattainable future trajectories may be predicted~\citep{Markovsky2022}. On the other hand, if the data matrix is rank-deficient, then the \ac{DeePC} problem may be infeasible. To deal with noise, slack variables and regularization initially served as heuristic measures to introduce robustness~\citep{Coulson2019}, but have been motivated formally to, e.g., provide robust closed-loop stability guarantees~\citep{Berberich2021}, distributional robustness~\citep{Coulson2019a}, or robustness to structured uncertainty~\citep{Huang2023}. Other approaches to handle noise in direct data-driven methods have also been considered and include averaging techniques~\citep{Jo2022}, singular value based thresholding~\citep{Sassella2022}, and the use of maximum likelihood estimation~\citep{Yin2023}. See also~\cite{Sassella2023} for a discussion of such methods. 

A fundamentally different noise-mitigation technique is the use of \ac{IVs}. These are employed in~\cite{vanWingerden2022} to mitigate noise and to demonstrate the equivalence between \ac{DeePC} and a subspace identification-inspired direct data-driven method called \ac{SPC} from~\cite{Favoreel1999}. This equivalence between the two direct data-driven predictive control methods has  also been demonstrated when using regularizations to deal with noise, or in a deterministic setting~\citep{Fiedler2021}. The equivalence has many profound implications due to the connection with subspace identification, which has a strong fundamental basis.%is important because it means that results from the domain of subspace identification that underpin \ac{SPC} also apply to \ac{DeePC}.
% 
% In \cite{Favoreel1999} a direct data-driven approach called \ac{SPC} is developed based on a linear regression problem from subspace identification. Recently \ac{SPC} has been shown to be equivalent to \ac{DeePC} %is actually equivalent to another direct data-driven predictive control technique called \ac{SPC}, which as the name alludes to, finds its origin in the domain of subspace identification. This equivalence has been shown 
% both in noiseless settings and those with noise that employ regularizations~\citep{Fiedler2021} and \ac{IVs}~\citep{vanWingerden2022} as noise mitigation strategies. The aforementioned equivalence is important because it means that results from the domain of subspace identification that underpin \ac{SPC} also apply to \ac{DeePC}.

One such a result is that in closed-loop inputs become correlated with noise, resulting in closed-loop identification bias~\citep{Soderstrom1989a}. In \cite{Dinkla2023} it is demonstrated that this problem can arise with adaptive \ac{SPC} and (given the aforementioned equivalence also) \ac{DeePC} applications, potentially degrading controller performance. Two suggestions of the authors to tacke this issue concern the use of \ac{IVs}, which motivates the work of~\cite{Wang2023}, and the use of sequential step-ahead predictions. This latter suggestion motivates the concurrent work of~\cite{Shi2023} and is thoroughly developed here.
%In \citet{Wang2023} a \ac{CL-DeePC} algorithm is therefore developed that makes use of \ac{IVs} to solve this issue. Another solution to this problem is to avoid correlation between inputs and noise by using a one-step-ahead predictor~\citep{Ljung1996}. This idea is employed in~\cite{Dong2008} to develop \ac{CL-SPC}, which does not suffer from this closed-loop identification issue.

% To date all solutions of the closed-loop identification issue in direct data-driven predictive control applications are based on a subspace framework, as with \ac{CL-SPC}. Although the \textit{original} \ac{SPC} and \ac{DeePC} algorithms are equivalent, no behavioural approach has yet been developed that deals with closed-loop identification bias. \todo{behavi-oural treatment possible?}
To date all solutions to deal with noise in closed-loop direct data-driven predictive control are either based on a subspace framework, as with \ac{CL-SPC}, or rely on \ac{IVs} and controller knowledge to solve this issue in \ac{DeePC}. The aim of this article is to develop a \ac{CL-DeePC} method that does not rely \ac{IVs} to solve the aforementioned closed-loop identification issue, but may use \ac{IVs} as an additional noise-mitigation technique.
%To this end, the aim of this paper is to develop a \ac{CL-DeePC}\footnote{Henceforth this abbreviation will be used to distinguish it from regular \ac{DeePC}, as developed in~\citep{Coulson2019}.} method that does not suffer from the aforementioned closed-loop identification issue.
In doing so, the main contributions of this article are: %
\begin{enumerate}%
\item the development of \ac{CL-DeePC} by sequential application of a step-ahead predictor that solves the closed-loop identification problem that arises in the presence of noise, \label{contribution:solves_CL_issue}
\item the evaluation of different possible \ac{CL-DeePC} implementations,
\item the incorporation of \ac{IVs} in \ac{CL-DeePC} as a systematic noise-mitigation technique,
\item to establish an equivalence between the developed \ac{CL-DeePC} algorithm and \ac{CL-SPC},
\item to show the superior performance of \ac{CL-DeePC} compared to \ac{DeePC} in a simulation example.
\end{enumerate}
% 
% \begin{enumerate}
%     \item implicitly enforces a causal multi-step ahead predictor model, and \label{contribution:causality}
%     \item is particularly sample-efficient (taken to mean here that it requires less past data) compared to regular \ac{DeePC}, \label{contribution:sample_efficient}
% \end{enumerate}