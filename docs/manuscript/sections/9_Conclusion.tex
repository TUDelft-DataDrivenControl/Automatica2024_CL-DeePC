\section{Conclusion}
\noindent This article develops \ac{CL-DeePC} to address a closed-loop identification issue that is inherent to adaptive \ac{DeePC} implementations. By incorporating \ac{IVs} to mitigate noise it is shown that (unlike \ac{DeePC}) \ac{CL-DeePC} employs a consistent output predictor when relying on data obtained in closed-loop. Moreover, to limit the number of optimization variables, an efficient sequential procedure is established to construct the output predictor in practice. This sequential procedure reveals the equivalence of the developed \ac{CL-DeePC} method and \ac{CL-SPC}.

Simulations confirm that, unlike \ac{DeePC}, \ac{CL-DeePC} relies on data that does not exhibit correlation between inputs and preceding noise, facilitating the use of a consistent output predictor. Furthermore simulations demonstrate superior reference tracking performance of \ac{CL-DeePC} compared to \ac{DeePC}. A sensitivity analysis illustrates that \ac{CL-DeePC} is more sample efficient than \ac{DeePC}, less sensitive to high noise levels, and performs better for a wide range of past prediction window lengths $p=f$. Where this work has considered a single choice of \ac{IV} ($\mathcal{Z}=\Psi_{i,1,N}$), future work may consider different \ac{IVs} in \ac{CL-DeePC} to further reduce the effects of noise.