\section{Preliminaries, definitions and notation}
This section presents the employed system model and the notation that is used in this article.

\subsection{System model}
Consider a non-deterministic discrete \ac{LTI} system $\mathcal{S}$ whose dynamics is described in the so-called \textit{innovation} form by
\begin{subequations}\label{eqn:SS_innovation}
\begin{empheq}[left=\mathcal{S}_\mathcal{I}\empheqlbrace]{align}
    x_{k+1} &= Ax_k + Bu_k + Ke_k,\label{eqn:SSi_x}\\
	y_k &= Cx_k + Du_k + e_k \label{eqn:SSi_y},
  \end{empheq}
\end{subequations}
in which the subscript $k$ denotes the discrete time index, ${x_k\in\mathbb{R}^n}$, ${u_k\in\mathbb{R}^r}$, ${y_k\in\mathbb{R}^l}$, ${e_k\in\mathbb{R}^l}$ respectively represent states, inputs, outputs, and zero-mean white innovation noise with variance $R > 0$, and $\{A,B,C,D,K\}$ are system matrices of compatible dimensions. Without loss of generality\todo{really?} we henceforth assume the data to be generated by a minimal system realization. %also done in Breschi2022
In accordance with Kalman filtering theory from which this representation derives, $K$ represents a unique (and optimal) Kalman filter gain matrix that renders ${\tilde{A}=A-KC}$ asymptotically stable (see, e.g., \citet[Sec.~5.7]{Verhaegen2007a}). By substituting \eqnref{eqn:SSi_y} into \eqnref{eqn:SSi_x} one alternatively obtains the equivalent predictor form
\begin{subequations}\label{eqn:SS_predictor}
\begin{empheq}[left=\mathcal{S}_\mathcal{P}\empheqlbrace]{align}
	x_{k+1} &= \tilde{A}x_k + \tilde{B}u_k + Ky_k,\label{eqn:SSp_x}\\
	y_k &= Cx_k + Du_k + e_k \label{eqn:SSp_y},
  \end{empheq}
% \begin{align}
	% x_{k+1} &= \tilde{A}x_k + \tilde{B}u_k + Ky_k,\label{eqn:SSp_x}\\
	% y_k &= Cx_k + Du_k + e_k \label{eqn:SSp_y},
% \end{align}
\end{subequations}
in which $\tilde{B}=B-KD$.
%
% ${x_k\in\mathbb{R}^n}$, ${e_k\in\mathbb{R}^l}$, and $K\in\mathbb{R}^{n\times l}$ respectively represent states, zero-mean white innovation noise, and a unique Kalman gain matrix that renders ${\tilde{A}=A-KC}$ asymptotically stable.
%
% in which ${\bar{x}_k\in\mathbb{R}^n}$, ${u_k\in\mathbb{R}^r}$, ${y_k\in\mathbb{R}^l}$, ${w_k\in\mathbb{R}^n}$, ${v_k\in\mathbb{R}^l}$ respectively represent states, inputs, outputs, process noise, and measurement noise, and $\{A,B,C,D\}$ are system matrices of compatible dimensions. If the process and measurement noise are either zero-mean white or colored Gaussian sequences such that the system $\mathcal{S}$ satisfies notions of detectability and reachability there exists an equivalent innovation form $\mathcal{F}_\mathcal{I}$ that is based on Kalman filtering (see~\citet[p.~112-113\todo{Check pages}]{Anderson1979}, or \citet[p.~162]{Verhaegen2007a} for details) and is given by
%
\subsection{Definitions and notation}\label{sec:notation}
Having described the different representations of the considered discrete, non-deterministic \ac{LTI} systems, this section introduces the notation and several definitions that are used in this work.

To start, several strictly-positive integers are denoted by $s,q,p,f,N\in\mathbb{Z}_{>0}$ and are frequently used to indicate window lengths. Throughout this article, time indices $i$, $\hat{i}$, and $k$, will be used together with the shorthand exemplified by $k_p=k+p$.

Block-Toeplitz matrices are defined by
\begin{align}\label{eqn:blockToeplitz} 
\mathcal{T}_s(\mathcal{A},\mathcal{B},\mathcal{C},\mathcal{D}) =\scriptsize{
	\begin{bmatrix}
		\mathcal{D}         & \mathcal{O}         & \mathcal{O}      & \cdots  & \mathcal{O}\\
		\mathcal{C}\mathcal{B}        & \mathcal{D}         & \mathcal{O}      & \cdots  & \mathcal{O}\\
		\mathcal{C}\mathcal{A}\mathcal{B}       & \mathcal{C}\mathcal{B}        & \mathcal{D}      & \cdots & \mathcal{O}\\
		\vdots    &  \vdots & \ddots & \ddots & \vdots\\
		\mathcal{C}\mathcal{A}^{s-2}\mathcal{B} & \mathcal{C}\mathcal{A}^{s-3}\mathcal{B} & \cdots  & \mathcal{C}\mathcal{B}     & \mathcal{D}
	\end{bmatrix}},
\end{align}
in which the subscript $s$ indicates the number of block-rows, the matrices $\mathcal{A}$, $\mathcal{B}$, $\mathcal{C}$, $\mathcal{D}$, and the null matrix $\mathcal{O}$ are all of compatible dimensions. Let ${I_s\in\mathbb{R}^{s\times s}}$ represent an identity matrix. Equation~\eqnref{eqn:blockToeplitz} thereby defines the block-Toeplitz matrices
\begin{alignat*}{2}
\mathcal{T}_s^\mathrm{u}&=\mathcal{T}_s(A,B,C,D),\quad  &\mathcal{H}_s&=\mathcal{T}_s(A,K,C,I_l),\\
\widetilde{\mathcal{T}}_s^\mathrm{u}&=\mathcal{T}_s(\tilde{A},\tilde{B},C,D),\quad  &\widetilde{\mathcal{H}}_s&=\mathcal{T}_s(\tilde{A},K,-C,I_l).
\end{alignat*}

In addition, two extended observability matrices are defined by
\begin{align*}
\Gamma_s &= \begin{bmatrix}C^\top & (CA)^\top & \cdots & (CA^{s-1})^\top\end{bmatrix}^\top,\\%\quad\text{and}\\
\widetilde{\Gamma}_s &= \begin{bmatrix}C^\top & (C\tilde{A})^\top & \cdots & (C\tilde{A}^{s-1})^\top\end{bmatrix}^\top.
\end{align*}
The extended observability matrix $\Gamma_s$ is used to define a system property commonly referred to as its lag.
\begin{defn}\label{def:lag}
    A system's lag is the smallest integer $\ell\in\mathbb{Z}_{>0}$ such that the extended observability matrix $\Gamma_\ell$ is of rank $n$.
\end{defn}

Moreover, two extended reversed controllability matrices are defined as 
\begin{align*}
\tKp{u} &= \begin{bmatrix} \tilde{A}^{p-1}\tilde{B}\:\, & \tilde{A}^{p-2}\tilde{B} & \cdots & \tilde{A}\tilde{B} & \tilde{B}\:\, \end{bmatrix},\\%\text{ and}\\
\tKp{y} &= \begin{bmatrix} \tilde{A}^{p-1}K & \tilde{A}^{p-2}K & \cdots & \tilde{A}K & K \end{bmatrix}.
\end{align*}

From the above matrices, two reoccurring so called `dynamic matrices' are defined as
\begin{align*}
    L_s &= \begin{bmatrix} \Gamma_s\tKp{u} & \mathcal{T}_s^\mathrm{u} & \Gamma_s\tKp{y} \end{bmatrix},\\%\text{ and}\\
    \widetilde{L}_s &= \begin{bmatrix} \widetilde{\Gamma}_s\tKp{u} & \widetilde{\mathcal{T}}_s^\mathrm{u} & \widetilde{\Gamma}_s\tKp{y} \end{bmatrix}.
\end{align*}
%
Furthermore, data vectors are denoted as examplified by
\begin{align*}
    \datavec{u}{k,s} = \begin{bmatrix} u_k^\top & u_{k+1}^\top & \cdots & u_{k+s-1}^\top\end{bmatrix}^\top,
\end{align*}
which represents a vector of ordered input data starting at time index $k$, and containing a number of samples $s$.

Using such data vectors it is possible to concisely define block-Hankel data matrices. Such a block-Hankel data matrix is examplified by
\begin{align*}
    U_{k,s,q} = \begin{bmatrix}
        \datavec{u}{k,s} & \datavec{u}{k+1,s} & \cdots & \datavec{u}{k+q-1,s}
    \end{bmatrix},
\end{align*}
which contains $q$ successive input data vectors with $p$ data samples each, starting from time index $k$, and have a block-anti diagonal structure. This notion of block-Hankel data matrices is employed to define the notion of persistency of excition.
\begin{defn}\label{def:PE}
    An input sequence $u_{k},u_{k+1},\dots,u_{k+s+q-2}$ is persistently exciting of order $s$ if the matrix $U_{k,s,q}$ is of full row rank.
\end{defn}
Data vectors and block-Hankel data matrices that contain only predictions are indicated by $\hat{(\cdot)}$ whilst those that are comprised in part of predictions are indicated by $\tilde{(\cdot)}$.

For convenience, the notation $\Phi$ is reserved to denote an often encountered concatenation of input and output block-Hankel matrices that is given by
\begin{align*}
    \Phi_{k,s,q} = \begin{bmatrix}
        U_{k,p,q}^\top & U_{k_p,s,q}^\top & Y_{k,p,q}^\top
    \end{bmatrix}^\top,
\end{align*}
in which $k$, and $q$ respectively indicate the starting index and parameterize the dimensions of the concatenated matrix together with $p$.